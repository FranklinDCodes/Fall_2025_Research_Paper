\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Stock Market Trading with LSTM Analysis\\
}

% \thanks{Identify applicable funding agency here. If none, delete this.}
% }

\author{\IEEEauthorblockN{Franklin Doane}
\IEEEauthorblockA{\textit{dept. of Computer Science} \\
\textit{Tennessee Technological University}\\
Cookeville, United States \\
fgdoane42@tntech.edu}
}

\maketitle

% \begin{abstract}
% This document is a model and instructions for \LaTeX.
% This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes, 
% or Math in Paper Title or Abstract.
% \end{abstract}

% \begin{IEEEkeywords}
% component, formatting, style, styling, insert
% \end{IEEEkeywords}

\section{Dataset Creation}
\subsection{Find stocks by market cap}
    I downloaded a list of all stocks ranked by market cap off the internet
\subsection{Select largest stocks with sufficient data}
    Next, I used the list along with the yahoo finance api to select the 1500 most valuable companies that satisfied the following conditions: data for training dating back to the beginning of 2011, and additional data before that sufficient for indicator calculation and for creating the first time-series input with Jan 01 2011 as it's last date.
\subsection{Download train and test data}
    I used 10 training datasets, the first one containing data for all market days in 2011-2012, with each following adding 1 sequential year of data. There are 10 evaluation sets, each contain data for a single year, from 2014 - 2023. Each training set and testing set downloaded data for every stock in the list using the yahoo finance api. All data is made up of 1 day candlesticks. Each download with the size of the dataset, with additional older data sufficient for calculating indicators and for supplying the 50 day history for the first day of the year.


\section{Training Setup}
\subsection{Load dataset}
    Dataset is loaded from csv files.
\subsection{Calculate additional features}
    The only additional feature calculated on the data is the day of the week 1-hot-encoded into 5 separate features.
\subsection{Slice into training examples}
    The data then gets cut into time series, each with a length of 50. The data from the day following each time series is used to create the label, which consist of the relative increase in high price and low price compared to the close price of the previous day. The training examples from each stock get concatenated together into 1 dataset.
\subsection{Seperate validation set}
    Once all the training examples have been created, 15\% of the training examples are sliced off of the back of the dataset to become the validation set. The rest of the examples is the training set.
\subsection{Shuffle training data}
    The ordering of the training set gets shuffled.
\subsection{Split batches}
    The training data gets split into whole batches of size 200.
\subsection{Initialize model}
    The model is initialized with random parameters. The model is an LSTM with 1 hidden layer of size 64. The output of the LSTM is fed into the following sequence: 
    \begin{align} 
    &Fully\_Connected(64 \to 32)& \\ &Leaky\_ReLU(leak = 1e^{-5})& \\ &Fully\_Connected(32 \to 2)&
    \end{align}

\section{Training Loop (per epoch)}
\subsection{Calculate loss}
    The loss for each batch is calculated with the following formula. The formula utilizes Mean Squared Error loss and a magnitude penalty for the logits.
    \begin{equation}
        Loss = mse(Y, \hat{Y}) + \lambda\sum_{i=1}^{B}(\hat{Y}_{i, 1}) - \lambda\sum_{i=1}^{B}(\hat{Y}_{i, 2})
    \end{equation}
    Here the first logit is the high price that the model is predicting, and the second is the low price. B represents the batch size, and $\lambda$ is the magnitude penalty coefficient.
\subsection{Optimize}
    The loss is backpropagated for each batch, and the parameters are updated with the Adam optimizer. The learning rate for the optimizer starts at 1e-3, and is set by the PyTorch LowerOnPlateau scheduler. The metric tracked by the scheduler is validation loss.
\subsection{Validation}
    After all the batches are used for training, validation occurs. The model predicts all of the examples in the validation set and loss is calculated. Unlike during training, the loss in validation is calculated as a pure Mean Squared Error loss with no magnitude penalties. The loss is then used to update the learning rate scheduler.

% \subsection{Setup regulator}
% \subsubsection{Init regulator}
%     Pass starting learning rate and other kwargs from config
% \subsection{Load dataset}
% \subsubsection{Init dataset object}
%     The dataset object is initialized and given config. Then the load dataset method is called which does the following.
% \subsubsection{Verify files}
%     Loads all csvs in dataset and verifies a minimum length. A legacy feature at this point.
% \subsubsection{Split files into task groups}
%     List of valid files is split into groups to have each group loaded with threads.
% \subsubsection{Open dataset thread pool}
%     Open thread pool to load files.
% \subsubsection{Load csv files}
%     Open every file from directory listed in config. Load as pandas dataframe with date index column and put them all in a list.
% \subsubsection{Calculate indicators}
%     Calculate all additional features listed in configs. Cut out any data at the front of the dataframes that is missing these features (e.g. for rolling avgs).
% \subsubsection{Create date feature}
%     1hot encode day of the week and add the new weekday features to all dataframes.
% \subsubsection{Slice data into training examples}
%     Use rolling window to cut each dataframe into training example dataframes with n day history. All examples get added to a list and labels are made into a dataframe of their own.
% \subsubsection{Normalize examples}
%     Each dataframe training example is normalized using norm function from config.
% \subsubsection{Create tensor input}
%     Each dataframe is converted to numpy then a tensor with the datatype and device listed in the config. All labels are converted a single tensor as well.
% \subsection{Load model}
% \subsubsection{Dynamically load model class}
%     The Python file containing the model class is loaded by name using importlib.
% \subsubsection{Call init}
%     Init custom model class. The custom model class is passed a name, starting LR, and input feature count from dataset. The model inherits from torch.nn.Module which is also inited.
% \subsubsection{Setup pytorch objects}
%     Model class init sets up LSTM object and Sequential object for forward passes, a default optimizer, a null loss func and an empty history.
% \subsubsection{Set optimizer}
%     Call model set optim method to initialize and save optimizer to model class.
% \subsubsection{Send to device}
%     Set model to device specified in config.
% \subsection{Setup scheduler}
% \subsubsection{Init scheduler}
%     Pass optimizer from model. Give it kwargs from config
% \subsection{Setup dataloader}
% \subsubsection{Check for test set}
%     Check's to see if the model save config contains test set indices. For loading a partially trained model. Indices get set after init if none are there. Pretty much a vestigial feature.
% \subsubsection{Call init}
%     Init object and pass in dataset object (and test set indices if applicable)
% \subsubsection{Pick test indices}
%     If not test set indices were passed, create list of indices and either random sample indices (legacy) or slice chunk off the front to create test set indices.
% \subsubsection{Seperate test set}
%     Use indices to make a mask and remove test examples from all indices to get training set indices
% \subsubsection{Shuffle train set}
%     random.shuffle train set indices
% \subsubsection{Split batches}
%     Split train set indices into batches using a list comprehension and slicing with option to drop last partial batch. Transforms list[int] -> list[list[int]]. Casts result to tensor.
% \subsubsection{Setup first inputs}
%     Create empty list for inputs and labels. Prefetch first n batches by indexing them out of dataset and adding them to input and label sets. Remove these indices from batch indices.
% \subsubsection{Load test set}
%     Index test set and labels out of data and Store
% \section{Training Loop (per epoch)}
% \subsection{Setup}
% \subsubsection{Get regulator coefs}
%     Pass regulator lr and get the coefficient for each logit. Coefficients will be stepped down if LR has changed
% \subsubsection{Update loss}
%     Call function to init custom MSE loss and pass it the regularization coefficients. Call method to set new loss for model class.
% \subsection{Train batches}
% \subsubsection{Unpack dataloader}
%     Each iteration grabs a batch from the loaded set of batches. If the loaded set is empty, the dataloader loads indexes more batches out of the dataset. Continues until all batch indices are popped.
% \subsubsection{Forward pass}
%     Call model forward with batch inputs
% \subsubsection{Call backward pass}
%     Pass model backpass method the logits and batch labels (with added time series dimension). Starts by putting model in train mode.
% \subsubsection{Calc loss}
%     Zero optimizer gradient then run model's built-in loss function. Backwards' the loss.
% \subsubsection{Optimize}
%     Step optimizer.
% \subsection{Save}
% \subsubsection{Checkpoint model}
%     Save epoch copy of model as pkl to model save dir. Includes model params as well as model training history.
% \subsection{Validation}
% \subsubsection{Eval setup}
%     Set model in eval mode. Create data structures for saving outcomes and losses.
% \subsubsection{Open each item in test set}
%     Iterate over test set inputs and labels. Do the following for each one
% \subsubsection{Forward pass}
%     Call model on test input
% \subsubsection{Calculate loss}
%     Grab close price (3rd label item), and pass high and low price into loss function
% \subsubsection{Update outcome counts}
%     Decipher outcome as either win, stop-loss, both (loss), neither, missed win, missed loss, missed stop-loss, missed both, or missed neither. Also update the count for the broader category of loss, and update the counts for why the win was missed (predicted stop-loss, predicted neither, predicted both).
% \subsubsection{Final calculations}
%     After all examples are run through, calculate the following statistics: win rate, random win rate, guess rate, average timeout, and average eval loss
% \subsubsection{Update scheduler}
%     Send average example loss to scheduler.

% \section{Evaluation Setup}
% \subsection{Load configs}
% \subsubsection{Load eval config}
%     Load config as JSON object.
% \subsubsection{Unpack eval config}
%     Unpack values from config as variables.
% \subsubsection{Load training config}
%     Load the config that was used for training the model as a JSON object.
% \subsection{Load model}
% \subsubsection{Dynamically load model class}
%     The Python file containing the model class is loaded by name using importlib.
% \subsubsection{Call init}
%     Init custom model class. The custom model class is passed a name, starting LR of 0, and input feature count from config. The model inherits from torch.nn.Module which is also inited.
% \subsubsection{Load model save}
%     Loads model params from pkl file.
% \subsection{Start agent}
% \subsubsection{Call agent init}
%     Initialize agent object and pass config, model, and starting balance.
% \subsubsection{Unpack agent parameters}
%     Agent init unpacks all of it's rules for buying and selling from config.
% \subsubsection{Create data structures}
%     Agent init creates empty data structures for tracking outcomes, balance, owned stocks, and labels for owned stocks.
% \subsection{Load dataset}
% \subsubsection{Init dataset and load}
%     The dataset object is initialized and given config. The load method is called which does the following.
% \subsubsection{Read csvs}
%     The dataset object reads all csvs in dataset directory and store them in a dict with the format \{"ticker": dataframe\}
% \subsubsection{Calculate additional features}
%     Iterate through dataset keys and calc all additional features specified in training config.
% \subsubsection{1-hot encode dates}
%     For each dataframe in dataset, keep date column as index but add 1-hot encoded day of the week columns.
% \subsubsection{Setup comparison stock}
%     Look for saved file of balances from investing with comparison stock (e.g. S\&P). If not, load comparison stock data from dataset.
% \subsection{Setup for iteration}
% \subsubsection{Init date range object}
%     Initialize custom date range iterator and pass it the start and end dates to iterate over. Each date in the iteration will be the day to predict the outcome of.
% \section{Evaluation loop (per day in date range)}
% \subsection{Get inputs}
% \subsubsection{Attempt to index date}
%     For each stock dataframe, attempt to index the current date in the simulation. If it fails, return no data (common for weekends or holidays).
% \subsubsection{Get input sequence}
%     If date was indexed successfully, grab 50 day sequence prior for model input.
% \subsubsection{Get last price}
%     Index the close price of last day of sequence. This will be considered the purchase price if stock is purchased.
% \subsubsection{Normalize input sequence}
%     Use normalization function from training to normalize sequence.
% \subsubsection{Turn input into tensor}
%     Drop date string index column from dataframe and convert to torch tensor.
% \subsubsection{Get label data}
%     Index current date row out of dataframe and turn into dict to use for labels.
% \subsubsection{Compile data}
%     Put all inputs and label from all stocks for the day into an iterable.
% \subsection{Iterate through inputs (for each stock)}
% \subsubsection{Unpack data}
%     Unpack stock ticker, input, final price in input sequence, and day candlestick (labels).
% \subsubsection{Forward pass}
%     Forward pass input through model.
% \subsubsection{Save data}
%     Save model logits, and all other unpacked stock data into data structures.
% \subsection{Purchase}
% \subsubsection{Call agent buy}
%     Tell agent to make purchases. Pass model predictions and labels.
% \subsubsection{Filter predictions}
%     The agent buy function filters predictions for ones that meet the criteria for purchasing.
% \subsubsection{Allocate funds}
%     If there are stocks that meet the criteria, divide current amongst them equally. Agent will remove stocks if there are too many to have minimum \$1 per purchase.
% \subsubsection{Finalize purchases}
%     Add purchased stocks and their purchase amount to agent stocks. Save label data as well.
% \subsection{Sell}
% \subsubsection{Call agent sell}
%     Tell agent to sell stocks.
% \subsubsection{Calculate aim prices}
%     Calculate prices that agent aims to sell stocks at, as well as prices it will stop loss at.
% \subsubsection{Calculate increases}
%     Use label data to calculate what the increase (positive or negative) would've been for each stock.
% \subsubsection{Calculate sale totals}
%     Use buy totals and increases to calculate sale totals. Sum them to get new balance.
% \subsubsection{Update outcome counts}
%     Update agent's stored counts of different outcome types for statistical analysis.
% \subsubsection{Update increase averages}
%     Update agent's stored averages of increase percentages for different outcome types.
% \subsubsection{Remove agent stocks}
%     Remove all stocks and labels from agent's owned list.
% \subsection{Update}
% \subsubsection{Update agent history}
%     Add new balance, buy count, and increases to history for charting.
% \subsubsection{Update comparison stock}
%     If generating data to compare to agent, calculate what the stocks increase would've been and update balance.
% \section{Evaluation aftermath}
% \subsection{Files}
% \subsubsection{Calculate win rate}
%     Use outcome counts to calculate win rate.
% \subsubsection{Save all data}
%     Save balances, buy counts, increases, outcome counts, and generated comparison data to results directory.
% \subsection{Charts}
% \subsubsection{Create and save charts}
%     Generate chart and save to results directory.

    

% \section{Ease of Use}

% \subsection{Maintaining the Integrity of the Specifications}

% The IEEEtran class file is used to format your paper and style the text. All margins, 
% column widths, line spaces, and text fonts are prescribed; please do not 
% alter them. You may note peculiarities. For example, the head margin
% measures proportionately more than is customary. This measurement 
% and others are deliberate, using specifications that anticipate your paper 
% as one part of the entire proceedings, and not as an independent document. 
% Please do not revise any of the current designations.

% \section{Prepare Your Paper Before Styling}
% Before you begin to format your paper, first write and save the content as a 
% separate text file. Complete all content and organizational editing before 
% formatting. Please note sections \ref{AA}--\ref{SCM} below for more information on 
% proofreading, spelling and grammar.

% Keep your text and graphic files separate until after the text has been 
% formatted and styled. Do not number text heads---{\LaTeX} will do that 
% for you.

% \subsection{Abbreviations and Acronyms}\label{AA}
% Define abbreviations and acronyms the first time they are used in the text, 
% even after they have been defined in the abstract. Abbreviations such as 
% IEEE, SI, MKS, CGS, ac, dc, and rms do not have to be defined. Do not use 
% abbreviations in the title or heads unless they are unavoidable.

% \subsection{Units}
% \begin{itemize}
% \item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
% \item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
% \item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
% \item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
% \end{itemize}

% \subsection{Equations}
% Number equations consecutively. To make your 
% equations more compact, you may use the solidus (~/~), the exp function, or 
% appropriate exponents. Italicize Roman symbols for quantities and variables, 
% but not Greek symbols. Use a long dash rather than a hyphen for a minus 
% sign. Punctuate equations with commas or periods when they are part of a 
% sentence, as in:
% \begin{equation}
% a+b=\gamma\label{eq}
% \end{equation}

% Be sure that the 
% symbols in your equation have been defined before or immediately following 
% the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at 
% the beginning of a sentence: ``Equation \eqref{eq} is . . .''

% \subsection{\LaTeX-Specific Advice}

% Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
% of ``hard'' references (e.g., \verb|(1)|). That will make it possible
% to combine sections, add equations, or change the order of figures or
% citations without having to go through the file line by line.

% Please don't use the \verb|{eqnarray}| equation environment. Use
% \verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
% environment leaves unsightly spaces around relation symbols.

% Please note that the \verb|{subequations}| environment in {\LaTeX}
% will increment the main equation counter even when there are no
% equation numbers displayed. If you forget that, you might write an
% article in which the equation numbers skip from (17) to (20), causing
% the copy editors to wonder if you've discovered a new method of
% counting.

% {\BibTeX} does not work by magic. It doesn't get the bibliographic
% data from thin air but from .bib files. If you use {\BibTeX} to produce a
% bibliography you must send the .bib files. 

% {\LaTeX} can't read your mind. If you assign the same label to a
% subsubsection and a table, you might find that Table I has been cross
% referenced as Table IV-B3. 

% {\LaTeX} does not have precognitive abilities. If you put a
% \verb|\label| command before the command that updates the counter it's
% supposed to be using, the label will pick up the last counter to be
% cross referenced instead. In particular, a \verb|\label| command
% should not go before the caption of a figure or a table.

% Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
% will not stop equation numbers inside \verb|{array}| (there won't be
% any anyway) and it might stop a wanted equation number in the
% surrounding equation.

% \subsection{Some Common Mistakes}\label{SCM}
% \begin{itemize}
% \item The word ``data'' is plural, not singular.
% \item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
% \item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
% \item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
% \item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
% \item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
% \item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
% \item Do not confuse ``imply'' and ``infer''.
% \item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
% \item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
% \item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
% \end{itemize}
% An excellent style manual for science writers is \cite{b7}.

% \subsection{Authors and Affiliations}
% \textbf{The class file is designed for, but not limited to, six authors.} A 
% minimum of one author is required for all conference articles. Author names 
% should be listed starting from left to right and then moving down to the 
% next line. This is the author sequence that will be used in future citations 
% and by indexing services. Names should not be listed in columns nor group by 
% affiliation. Please keep your affiliations as succinct as possible (for 
% example, do not differentiate among departments of the same organization).

% \subsection{Identify the Headings}
% Headings, or heads, are organizational devices that guide the reader through 
% your paper. There are two types: component heads and text heads.

% Component heads identify the different components of your paper and are not 
% topically subordinate to each other. Examples include Acknowledgments and 
% References and, for these, the correct style to use is ``Heading 5''. Use 
% ``figure caption'' for your Figure captions, and ``table head'' for your 
% table title. Run-in heads, such as ``Abstract'', will require you to apply a 
% style (in this case, italic) in addition to the style provided by the drop 
% down menu to differentiate the head from the text.

% Text heads organize the topics on a relational, hierarchical basis. For 
% example, the paper title is the primary text head because all subsequent 
% material relates and elaborates on this one topic. If there are two or more 
% sub-topics, the next level head (uppercase Roman numerals) should be used 
% and, conversely, if there are not at least two sub-topics, then no subheads 
% should be introduced.

% \subsection{Figures and Tables}
% \paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
% bottom of columns. Avoid placing them in the middle of columns. Large 
% figures and tables may span across both columns. Figure captions should be 
% below the figures; table heads should appear above the tables. Insert 
% figures and tables after they are cited in the text. Use the abbreviation 
% ``Fig.~\ref{fig}'', even at the beginning of a sentence.

% \begin{table}[htbp]
% \caption{Table Type Styles}
% \begin{center}
% \begin{tabular}{|c|c|c|c|}
% \hline
% \textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
% \cline{2-4} 
% \textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
% \hline
% copy& More table copy$^{\mathrm{a}}$& &  \\
% \hline
% \multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
% \end{tabular}
% \label{tab1}
% \end{center}
% \end{table}

% \begin{figure}[htbp]
% \centerline{\includegraphics{fig1.png}}
% \caption{Example of a figure caption.}
% \label{fig}
% \end{figure}

% Figure Labels: Use 8 point Times New Roman for Figure labels. Use words 
% rather than symbols or abbreviations when writing Figure axis labels to 
% avoid confusing the reader. As an example, write the quantity 
% ``Magnetization'', or ``Magnetization, M'', not just ``M''. If including 
% units in the label, present them within parentheses. Do not label axes only 
% with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization 
% \{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of 
% quantities and units. For example, write ``Temperature (K)'', not 
% ``Temperature/K''.

% \section*{Acknowledgment}

% The preferred spelling of the word ``acknowledgment'' in America is without 
% an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
% G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
% acknowledgments in the unnumbered footnote on the first page.

% \section*{References}

% Please number citations consecutively within brackets \cite{b1}. The 
% sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
% number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
% the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

% Number footnotes separately in superscripts. Place the actual footnote at 
% the bottom of the column in which it was cited. Do not put footnotes in the 
% abstract or reference list. Use letters for table footnotes.

% Unless there are six authors or more give all authors' names; do not use 
% ``et al.''. Papers that have not been published, even if they have been 
% submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
% that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
% Capitalize only the first word in a paper title, except for proper nouns and 
% element symbols.

% For papers published in translation journals, please give the English 
% citation first, followed by the original foreign-language citation \cite{b6}.

% \begin{thebibliography}{00}
% \bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
% \bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
% \bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
% \bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
% \bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
% \bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
% \bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
% \end{thebibliography}
% \vspace{12pt}
% \color{red}
% IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
